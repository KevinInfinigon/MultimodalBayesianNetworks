{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Import Libraries and Define Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic\n",
    "import pandas as pd\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torchmetrics\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Pyro: pip install pyro-ppl==1.8.4\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.distributions.constraints as constraints\n",
    "from pyro.infer import TraceEnum_ELBO, config_enumerate\n",
    "\n",
    "# others\n",
    "import os\n",
    "import albumentations\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import pathlib\n",
    "from typing import Tuple, Dict, List\n",
    "\n",
    "# data augmentation\n",
    "def get_transforms(image_size):\n",
    "    transforms_train = albumentations.Compose([\n",
    "        albumentations.Transpose(p=0.5),\n",
    "        albumentations.VerticalFlip(p=0.5),\n",
    "        albumentations.HorizontalFlip(p=0.5),\n",
    "        albumentations.RandomBrightness(limit=0.2, p=0.75),\n",
    "        albumentations.RandomContrast(limit=0.2, p=0.75),\n",
    "        albumentations.OneOf([\n",
    "            albumentations.MotionBlur(blur_limit=5),\n",
    "            albumentations.MedianBlur(blur_limit=5),\n",
    "            albumentations.GaussianBlur(blur_limit=5),\n",
    "            albumentations.GaussNoise(var_limit=(5.0, 30.0)),\n",
    "        ], p=0.7),\n",
    "        albumentations.OneOf([\n",
    "            albumentations.OpticalDistortion(distort_limit=1.0),\n",
    "            albumentations.GridDistortion(num_steps=5, distort_limit=1.),\n",
    "            albumentations.ElasticTransform(alpha=3),\n",
    "        ], p=0.7),\n",
    "        albumentations.CLAHE(clip_limit=4.0, p=0.7),\n",
    "        albumentations.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.5),\n",
    "        albumentations.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=0.85),\n",
    "        albumentations.Resize(image_size, image_size),\n",
    "        albumentations.Cutout(max_h_size=int(image_size*0.375), max_w_size=int(image_size*0.375), num_holes=1, p=0.7),\n",
    "        albumentations.Normalize(),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "    transforms_val = albumentations.Compose([\n",
    "        albumentations.Resize(image_size, image_size),\n",
    "        albumentations.Normalize(),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "    return transforms_train, transforms_val\n",
    "\n",
    "# 'torchvision.datasets.ImageFolder()' customized for applying data augmentation with albumentations library\n",
    "\n",
    "# make function to find classes in target directory\n",
    "def find_classes(directory: str) -> Tuple[List[str], Dict[str, int]]:\n",
    "    \"\"\"Finds the class folder names in a target directory.\n",
    "\n",
    "    Assumes target directory is in standard image classification format.\n",
    "\n",
    "    Args:\n",
    "        directory (str): target directory to load classnames from.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[str], Dict[str, int]]: (list_of_class_names, dict(class_name: idx...))\n",
    "    \n",
    "    Example:\n",
    "        find_classes(\"food_images/train\")\n",
    "        >>> ([\"class_1\", \"class_2\"], {\"class_1\": 0, ...})\n",
    "    \"\"\"\n",
    "    # 1. get the class names by scanning the target directory\n",
    "    classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
    "    \n",
    "    # 2. raise an error if class names not found\n",
    "    if not classes:\n",
    "        raise FileNotFoundError(f\"Couldn't find any classes in {directory}.\")\n",
    "        \n",
    "    # 3. create a dictionary of index labels (computers prefer numerical rather than string labels)\n",
    "    class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "    return classes, class_to_idx\n",
    "\n",
    "# write a customized dataset class (inherits from torch.utils.data.Dataset)\n",
    "# 1. subclass torch.utils.data.Dataset\n",
    "class CustomizedTextFolder(Dataset):\n",
    "    # 2. initialize with a targ_dir and a metadata_file\n",
    "    def __init__(self, img_dir: str, metadata_file) -> None:\n",
    "        # 3. create class attributes\n",
    "        # get all image paths\n",
    "        self.paths = list(pathlib.Path(img_dir).glob(\"*/*.jpg\")) # .png, .jpeg\n",
    "        # get metadata file path\n",
    "        self.metadata_file = metadata_file\n",
    "        # create classes and class_to_idx attributes\n",
    "        self.classes, self.class_to_idx = find_classes(img_dir)\n",
    "    # 3. overwrite the __len__() method (optional but recommended for subclasses of torch.utils.data.Dataset)\n",
    "    def __len__(self) -> int:\n",
    "        \"Returns the total number of samples.\"\n",
    "        return len(self.paths)\n",
    "    # 4. overwrite the __getitem__() method (required for subclasses of torch.utils.data.Dataset)\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
    "        \"Returns one sample of data, (metadata, label): (fv, y).\"\n",
    "        # load label\n",
    "        class_name  = self.paths[index].parent.name # expects path in data_folder/class_name/image.jpg(.png, .jpeg)\n",
    "        class_idx = self.class_to_idx[class_name]\n",
    "        label = class_idx\n",
    "        # load corresponding metadata\n",
    "        metadata_csv = pd.read_csv(self.metadata_file, index_col='img_id') # or other header names\n",
    "        img_id = self.paths[index].name.replace('.jpg', '') # .png, .jpeg\n",
    "        img_metadata = metadata_csv.loc[img_id]\n",
    "        metadata = torch.Tensor(img_metadata.values)\n",
    "        return metadata, label # return (metadata, label): (fv, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Load and Pre-Process the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 6\n",
    "\n",
    "fold = '_Fold1' # Stratified 5-Fold Cross Validation\n",
    "img_train_dir = '/.../PAD-UFES-20_300x300_SoG_Split4-1-1'+str(fold)+'/train/'\n",
    "img_val_dir = '/.../PAD-UFES-20_300x300_SoG_Split4-1-1'+str(fold)+'/val/'\n",
    "img_test_dir = '/.../PAD-UFES-20_300x300_SoG_Split4-1-1'+str(fold)+'/test/'\n",
    "metadata_file = '/.../metadata/metadata'+str(fold)+'.csv'\n",
    "\n",
    "ds_train = CustomizedTextFolder(img_train_dir, metadata_file)\n",
    "ds_val = CustomizedTextFolder(img_val_dir, metadata_file)\n",
    "ds_test = CustomizedTextFolder(img_test_dir, metadata_file)\n",
    "\n",
    "dl_train = DataLoader(ds_train, batch_size=64, shuffle=True)\n",
    "dl_val = DataLoader(ds_val, batch_size=64, shuffle=False)\n",
    "dl_test = DataLoader(ds_test, batch_size=64, shuffle=False)\n",
    "\n",
    "# print('Examine Numerical Labels: ', ds_train.class_to_idx)\n",
    "# for embeddings, labels in dl_train:\n",
    "#     # shape of features: [batch_size; channels, height, width]\n",
    "#     print('Examine Batched Data Shapes: ', embeddings.shape, labels.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Load and Fuse the Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUST CLEAR PARAM STORE BEFORE LOADING THE BEST PARAMS !!!\n",
    "pyro.clear_param_store()\n",
    "\n",
    "# load 2-class BN parameters\n",
    "best_params_2Class = torch.load('/.../checkpoints/2ClassBN'+str(fold)+'.pt')\n",
    "diagnosis_probs_param_2Class = best_params_2Class[6]\n",
    "itch_probs_param_2Class = best_params_2Class[0]\n",
    "grew_probs_param_2Class = best_params_2Class[1]\n",
    "hurt_probs_param_2Class = best_params_2Class[2]\n",
    "changed_probs_param_2Class = best_params_2Class[3]\n",
    "bleed_probs_param_2Class = best_params_2Class[4]\n",
    "elevation_probs_param_2Class = best_params_2Class[5]\n",
    "site_probs_param_2Class = best_params_2Class[7]\n",
    "diameter_probs_param_2Class = best_params_2Class[8]\n",
    "age_probs_param_2Class = best_params_2Class[9]\n",
    "# print('<<<<< 2-Class Concept BN >>>>>')\n",
    "# print('Diagnosis Probs: \\n', diagnosis_probs_param_2Class)\n",
    "# print('\\nItch Probs: \\n', itch_probs_param_2Class)\n",
    "# print('\\nGrew Probs: \\n', grew_probs_param_2Class)\n",
    "# print('\\nHurt Probs: \\n', hurt_probs_param_2Class)\n",
    "# print('\\nChanged Probs: \\n', changed_probs_param_2Class)\n",
    "# print('\\nBleed Probs: \\n', bleed_probs_param_2Class)\n",
    "# print('\\nElevation Probs: \\n', elevation_probs_param_2Class)\n",
    "# print('\\nSite Probs: \\n', site_probs_param_2Class)\n",
    "# print('\\nDiameter Probs: \\n', diameter_probs_param_2Class)\n",
    "# print('\\nAge Probs: \\n', age_probs_param_2Class)\n",
    "\n",
    "# load 4-class BN parameters\n",
    "best_params_4Class = torch.load('/.../checkpoints/4ClassBN'+str(fold)+'.pt')\n",
    "diagnosis_probs_param_4Class = best_params_4Class[6]\n",
    "itch_probs_param_4Class = best_params_4Class[0]\n",
    "grew_probs_param_4Class = best_params_4Class[1]\n",
    "hurt_probs_param_4Class = best_params_4Class[2]\n",
    "changed_probs_param_4Class = best_params_4Class[3]\n",
    "bleed_probs_param_4Class = best_params_4Class[4]\n",
    "elevation_probs_param_4Class = best_params_4Class[5]\n",
    "site_probs_param_4Class = best_params_4Class[7]\n",
    "diameter_probs_param_4Class = best_params_4Class[8]\n",
    "age_probs_param_4Class = best_params_4Class[9]\n",
    "# print('\\n<<<<< 4-Class Concept BN >>>>>')\n",
    "# print('Diagnosis Probs: \\n', diagnosis_probs_param_4Class)\n",
    "# print('\\nItch Probs: \\n', itch_probs_param_4Class)\n",
    "# print('\\nGrew Probs: \\n', grew_probs_param_4Class)\n",
    "# print('\\nHurt Probs: \\n', hurt_probs_param_4Class)\n",
    "# print('\\nChanged Probs: \\n', changed_probs_param_4Class)\n",
    "# print('\\nBleed Probs: \\n', bleed_probs_param_4Class)\n",
    "# print('\\nElevation Probs: \\n', elevation_probs_param_4Class)\n",
    "# print('\\nSite Probs: \\n', site_probs_param_4Class)\n",
    "# print('\\nDiameter Probs: \\n', diameter_probs_param_4Class)\n",
    "# print('\\nAge Probs: \\n', age_probs_param_4Class)\n",
    "\n",
    "# fuse into a 6-class BN without additional training\n",
    "diagnosis_probs_param = torch.cat((diagnosis_probs_param_4Class*2/3, diagnosis_probs_param_2Class/3), dim=1)\n",
    "itch_probs_param = torch.cat((itch_probs_param_4Class, itch_probs_param_2Class), dim=0)\n",
    "grew_probs_param = torch.cat((grew_probs_param_4Class, grew_probs_param_2Class), dim=0)\n",
    "hurt_probs_param = torch.cat((hurt_probs_param_4Class, hurt_probs_param_2Class), dim=0)\n",
    "changed_probs_param = torch.cat((changed_probs_param_4Class, changed_probs_param_2Class), dim=0)\n",
    "bleed_probs_param = torch.cat((bleed_probs_param_4Class, bleed_probs_param_2Class), dim=0)\n",
    "elevation_probs_param = torch.cat((elevation_probs_param_4Class, elevation_probs_param_2Class), dim=0)\n",
    "site_probs_param = torch.cat((site_probs_param_4Class, site_probs_param_2Class), dim=0)\n",
    "diameter_probs_param = torch.cat((diameter_probs_param_4Class, diameter_probs_param_2Class), dim=0)\n",
    "age_probs_param = torch.cat((age_probs_param_4Class, age_probs_param_2Class), dim=0)\n",
    "# print('<<<<< Fused Concept BN >>>>>')\n",
    "# print('Diagnosis Probs: \\n', diagnosis_probs_param)\n",
    "# print('\\nItch Probs: \\n', itch_probs_param)\n",
    "# print('\\nGrew Probs: \\n', grew_probs_param)\n",
    "# print('\\nHurt Probs: \\n', hurt_probs_param)\n",
    "# print('\\nChanged Probs: \\n', changed_probs_param)\n",
    "# print('\\nBleed Probs: \\n', bleed_probs_param)\n",
    "# print('\\nElevation Probs: \\n', elevation_probs_param)\n",
    "# print('\\nSite Probs: \\n', site_probs_param)\n",
    "# print('\\nDiameter Probs: \\n', diameter_probs_param)\n",
    "# print('\\nAge Probs: \\n', age_probs_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Build and Evaluate the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@config_enumerate\n",
    "def model(itch_obs, grew_obs, hurt_obs, changed_obs, bleed_obs, elevation_obs, site_obs, diameter_obs, age_obs, \n",
    "          C0_obs, C1_obs, C2_obs, C3_obs, C4_obs, \n",
    "          diagnosis_obs=None):\n",
    "    # parameters\n",
    "    # first layer \n",
    "    ### CNN latent variable: use the Softmax-ed output of CNN directly as the parameter of the distribution ###\n",
    "    # second layer\n",
    "    diagnosis_probs = pyro.param('diagnosis_probs', diagnosis_probs_param.cuda(), constraint=constraints.simplex)\n",
    "    # third layer\n",
    "    itch_probs = pyro.param('itch_probs', itch_probs_param.cuda(), constraint=constraints.simplex)\n",
    "    grew_probs = pyro.param('grew_probs', grew_probs_param.cuda(), constraint=constraints.simplex)\n",
    "    hurt_probs = pyro.param('hurt_probs', hurt_probs_param.cuda(), constraint=constraints.simplex)\n",
    "    changed_probs = pyro.param('changed_probs', changed_probs_param.cuda(), constraint=constraints.simplex)\n",
    "    bleed_probs = pyro.param('bleed_probs', bleed_probs_param.cuda(), constraint=constraints.simplex)\n",
    "    elevation_probs = pyro.param('elevation_probs', elevation_probs_param.cuda(), constraint=constraints.simplex)\n",
    "    site_probs = pyro.param('site_probs', site_probs_param.cuda(), constraint=constraints.simplex)\n",
    "    diameter_probs = pyro.param('diameter_probs', diameter_probs_param.cuda(), constraint=constraints.simplex)\n",
    "    age_probs = pyro.param('age_probs', age_probs_param.cuda(), constraint=constraints.simplex)\n",
    "\n",
    "    # distributions\n",
    "    # first layer\n",
    "    C0 = pyro.sample('Erythema', dist.Bernoulli(probs=C0_obs))\n",
    "    C1 = pyro.sample('Brown', dist.Bernoulli(probs=C1_obs))\n",
    "    C2 = pyro.sample('Crust', dist.Bernoulli(probs=C2_obs))\n",
    "    C3 = pyro.sample('Telangiectasia', dist.Bernoulli(probs=C3_obs))\n",
    "    C4 = pyro.sample('Nodule', dist.Bernoulli(probs=C4_obs))\n",
    "    # second layer\n",
    "    diagnosis = pyro.sample('diagnosis', dist.Categorical(probs=diagnosis_probs[(C4*16+C3*8+C2*4+C1*2+C0).long()]), obs=diagnosis_obs)\n",
    "    # third layer\n",
    "    itch = pyro.sample('itch', dist.Categorical(probs=itch_probs[(diagnosis).long()]), obs=itch_obs)\n",
    "    grew = pyro.sample('grew', dist.Categorical(probs=grew_probs[(diagnosis).long()]), obs=grew_obs)\n",
    "    hurt = pyro.sample('hurt', dist.Categorical(probs=hurt_probs[(diagnosis).long()]), obs=hurt_obs)\n",
    "    changed = pyro.sample('changed', dist.Categorical(probs=changed_probs[(diagnosis).long()]), obs=changed_obs)\n",
    "    bleed = pyro.sample('bleed', dist.Categorical(probs=bleed_probs[(diagnosis).long()]), obs=bleed_obs)\n",
    "    elevation = pyro.sample('elevation', dist.Categorical(probs=elevation_probs[(diagnosis).long()]), obs=elevation_obs)\n",
    "    site = pyro.sample('site', dist.Categorical(probs=site_probs[(diagnosis).long()]), obs=site_obs)\n",
    "    diameter = pyro.sample('diameter', dist.Categorical(probs=diameter_probs[(diagnosis).long()]), obs=diameter_obs)\n",
    "    age = pyro.sample('age', dist.Categorical(probs=age_probs[(diagnosis).long()]), obs=age_obs)\n",
    "    return diagnosis\n",
    "\n",
    "def guide(itch_obs, grew_obs, hurt_obs, changed_obs, bleed_obs, elevation_obs, site_obs, diameter_obs, age_obs, \n",
    "          C0_obs, C1_obs, C2_obs, C3_obs, C4_obs, \n",
    "          diagnosis_obs=None):\n",
    "    pass\n",
    "\n",
    "def predict(itch_obs, grew_obs, hurt_obs, changed_obs, bleed_obs, elevation_obs, site_obs, diameter_obs, age_obs, \n",
    "            C0_obs, C1_obs, C2_obs, C3_obs, C4_obs):\n",
    "    conditional_marginals = TraceEnum_ELBO().compute_marginals(model, guide, itch_obs=itch_obs, grew_obs=grew_obs, hurt_obs=hurt_obs, changed_obs=changed_obs, bleed_obs=bleed_obs, elevation_obs=elevation_obs, site_obs=site_obs, diameter_obs=diameter_obs, age_obs=age_obs, \n",
    "                                                               C0_obs=C0_obs, C1_obs=C1_obs, C2_obs=C2_obs, C3_obs=C3_obs, C4_obs=C4_obs)\n",
    "    diagnosis_prob_0 = conditional_marginals['diagnosis'].log_prob(torch.tensor(0).cuda()).exp().reshape(1, 1)\n",
    "    diagnosis_prob_1 = conditional_marginals['diagnosis'].log_prob(torch.tensor(1).cuda()).exp().reshape(1, 1)\n",
    "    diagnosis_prob_2 = conditional_marginals['diagnosis'].log_prob(torch.tensor(2).cuda()).exp().reshape(1, 1)\n",
    "    diagnosis_prob_3 = conditional_marginals['diagnosis'].log_prob(torch.tensor(3).cuda()).exp().reshape(1, 1)\n",
    "    diagnosis_prob_4 = conditional_marginals['diagnosis'].log_prob(torch.tensor(4).cuda()).exp().reshape(1, 1)\n",
    "    diagnosis_prob_5 = conditional_marginals['diagnosis'].log_prob(torch.tensor(5).cuda()).exp().reshape(1, 1)\n",
    "    diagnosis_probs = torch.cat((diagnosis_prob_0, diagnosis_prob_1, diagnosis_prob_2, diagnosis_prob_3, diagnosis_prob_4, diagnosis_prob_5), dim=0).T\n",
    "    diagnosis_preds = torch.argmax(diagnosis_probs, dim=1)\n",
    "    return diagnosis_preds, diagnosis_probs\n",
    "\n",
    "# calculate ACC, BACC, and AUROC\n",
    "ACC = torchmetrics.Accuracy(multiclass=True, num_classes=6, average='micro').cuda()\n",
    "BACC = torchmetrics.Accuracy(multiclass=True, num_classes=6, average='macro').cuda()\n",
    "AUROC = torchmetrics.AUROC(num_classes=6, average='macro').cuda()\n",
    "preds_all = torch.empty(0).cuda()\n",
    "probs_all = torch.empty(0).cuda()\n",
    "labels_all = torch.empty(0).cuda()\n",
    "for i in range(len(ds_test)):\n",
    "    # get one datapoint\n",
    "    embeddings, labels = ds_test[i]\n",
    "    embeddings = embeddings.cuda()\n",
    "    labels = torch.tensor(labels, dtype=torch.int8).reshape(1).cuda()\n",
    "    # assign data for BN\n",
    "    itch_obs = embeddings[0]\n",
    "    grew_obs = embeddings[1]\n",
    "    hurt_obs = embeddings[2]\n",
    "    changed_obs = embeddings[3]\n",
    "    bleed_obs = embeddings[4]\n",
    "    elevation_obs = embeddings[5]\n",
    "    site_obs = embeddings[6]\n",
    "    diameter_obs = embeddings[7]\n",
    "    age_obs = embeddings[8]\n",
    "    C0_obs = embeddings[9]\n",
    "    C1_obs = embeddings[10]\n",
    "    C2_obs = embeddings[11]\n",
    "    C3_obs = embeddings[12]\n",
    "    C4_obs = embeddings[13]\n",
    "    # calculate accuracy\n",
    "    preds, probs = predict(itch_obs, grew_obs, hurt_obs, changed_obs, bleed_obs, elevation_obs, site_obs, diameter_obs, age_obs, \n",
    "                           C0_obs, C1_obs, C2_obs, C3_obs, C4_obs)\n",
    "    preds_all = torch.cat((preds_all, preds))\n",
    "    probs_all = torch.cat((probs_all, probs))\n",
    "    labels_all = torch.cat((labels_all, labels))\n",
    "acc = ACC(preds_all.long(), labels_all.long())\n",
    "bacc = BACC(preds_all.long(), labels_all.long())\n",
    "auroc = AUROC(probs_all, labels_all.long())\n",
    "print('Test ACC: '+str((100*acc).item())+' %')\n",
    "print('Test BACC: '+str((100*bacc).item())+' %')\n",
    "print('Test AUROC: '+str((auroc).item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Save Classification Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_test = []\n",
    "id_test = []\n",
    "for i in range(len(ds_test)):\n",
    "    # get one datapoint\n",
    "    embeddings, _ = ds_test[i]\n",
    "    embeddings = embeddings.cuda()\n",
    "    # assign data for BN\n",
    "    itch_obs = embeddings[0]\n",
    "    grew_obs = embeddings[1]\n",
    "    hurt_obs = embeddings[2]\n",
    "    changed_obs = embeddings[3]\n",
    "    bleed_obs = embeddings[4]\n",
    "    elevation_obs = embeddings[5]\n",
    "    site_obs = embeddings[6]\n",
    "    diameter_obs = embeddings[7]\n",
    "    age_obs = embeddings[8]\n",
    "    C0_obs = embeddings[9]\n",
    "    C1_obs = embeddings[10]\n",
    "    C2_obs = embeddings[11]\n",
    "    C3_obs = embeddings[12]\n",
    "    C4_obs = embeddings[13]\n",
    "    _, probs = predict(itch_obs, grew_obs, hurt_obs, changed_obs, bleed_obs, elevation_obs, site_obs, diameter_obs, age_obs, \n",
    "                       C0_obs, C1_obs, C2_obs, C3_obs, C4_obs)\n",
    "    probs = probs.cpu().detach().numpy()\n",
    "    bn_test.append(probs)\n",
    "    id_test.append(os.path.basename(ds_test.paths[i]))\n",
    "bn_test = [row[0] for row in bn_test]\n",
    "bn_test = pd.DataFrame(data=bn_test).to_csv('bn_test.csv')\n",
    "id_test = pd.DataFrame(data=id_test).to_csv('id_test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d844e3f8642a194b776b23a167f67ed705eb7f693544df137c8957dd067974a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
