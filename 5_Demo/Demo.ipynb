{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Import Libraries and Define Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "import timm\n",
    "\n",
    "# Pyro: pip install pyro-ppl==1.8.4\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.distributions.constraints as constraints\n",
    "from pyro.infer import TraceEnum_ELBO, config_enumerate\n",
    "\n",
    "# others\n",
    "import os\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "from typing import Tuple, Dict, List\n",
    "import albumentations\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "# data augmentation\n",
    "def get_transforms(image_size):\n",
    "    transforms_train = albumentations.Compose([\n",
    "        albumentations.Transpose(p=0.5),\n",
    "        albumentations.VerticalFlip(p=0.5),\n",
    "        albumentations.HorizontalFlip(p=0.5),\n",
    "        albumentations.RandomBrightness(limit=0.2, p=0.75),\n",
    "        albumentations.RandomContrast(limit=0.2, p=0.75),\n",
    "        albumentations.OneOf([\n",
    "            albumentations.MotionBlur(blur_limit=5),\n",
    "            albumentations.MedianBlur(blur_limit=5),\n",
    "            albumentations.GaussianBlur(blur_limit=5),\n",
    "            albumentations.GaussNoise(var_limit=(5.0, 30.0)),\n",
    "        ], p=0.7),\n",
    "        albumentations.OneOf([\n",
    "            albumentations.OpticalDistortion(distort_limit=1.0),\n",
    "            albumentations.GridDistortion(num_steps=5, distort_limit=1.),\n",
    "            albumentations.ElasticTransform(alpha=3),\n",
    "        ], p=0.7),\n",
    "        albumentations.CLAHE(clip_limit=4.0, p=0.7),\n",
    "        albumentations.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.5),\n",
    "        albumentations.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=0.85),\n",
    "        albumentations.Resize(image_size, image_size),\n",
    "        albumentations.Cutout(max_h_size=int(image_size*0.375), max_w_size=int(image_size*0.375), num_holes=1, p=0.7),\n",
    "        albumentations.Normalize(),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "    transforms_val = albumentations.Compose([\n",
    "        albumentations.Resize(image_size, image_size),\n",
    "        albumentations.Normalize(),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "    return transforms_train, transforms_val\n",
    "\n",
    "# customized 'torchvision.datasets.ImageFolder()'\n",
    "\n",
    "# make function to find classes in target directory\n",
    "def find_classes(directory: str) -> Tuple[List[str], Dict[str, int]]:\n",
    "    \"\"\"Finds the class folder names in a target directory.\n",
    "\n",
    "    Assumes target directory is in standard image classification format.\n",
    "\n",
    "    Args:\n",
    "        directory (str): target directory to load classnames from.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[str], Dict[str, int]]: (list_of_class_names, dict(class_name: idx...))\n",
    "    \n",
    "    Example:\n",
    "        find_classes(\"food_images/train\")\n",
    "        >>> ([\"class_1\", \"class_2\"], {\"class_1\": 0, ...})\n",
    "    \"\"\"\n",
    "    # 1. get the class names by scanning the target directory\n",
    "    classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
    "    \n",
    "    # 2. raise an error if class names not found\n",
    "    if not classes:\n",
    "        raise FileNotFoundError(f\"Couldn't find any classes in {directory}.\")\n",
    "        \n",
    "    # 3. create a dictionary of index labels (computers prefer numerical rather than string labels)\n",
    "    class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "    return classes, class_to_idx\n",
    "\n",
    "# write a customized dataset class (inherits from torch.utils.data.Dataset)\n",
    "# 1. subclass torch.utils.data.Dataset\n",
    "class CustomizedImageFolder(Dataset):\n",
    "    # 2. initialize with a targ_dir, metadata_file and a transform parameter\n",
    "    def __init__(self, img_dir: str, metadata_file, transform) -> None:\n",
    "        # 3. create class attributes\n",
    "        # get all image paths\n",
    "        self.paths = list(pathlib.Path(img_dir).glob(\"*/*.jpg\")) # .png, .jpeg\n",
    "        # get metadata file path\n",
    "        self.metadata_file = metadata_file\n",
    "        # setup transforms\n",
    "        self.transform = transform\n",
    "        # create classes and class_to_idx attributes\n",
    "        self.classes, self.class_to_idx = find_classes(img_dir)\n",
    "    # 4. make function to load images\n",
    "    def load_image(self, index: int) -> Image.Image:\n",
    "        \"Opens an image via a path and returns it.\"\n",
    "        image_path = self.paths[index]\n",
    "        return Image.open(image_path) \n",
    "    # 5. overwrite the __len__() method (optional but recommended for subclasses of torch.utils.data.Dataset)\n",
    "    def __len__(self) -> int:\n",
    "        \"Returns the total number of samples.\"\n",
    "        return len(self.paths)\n",
    "    # 6. overwrite the __getitem__() method (required for subclasses of torch.utils.data.Dataset)\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
    "        \"Returns one sample of data, (img, metadata, label): (X, fv, y).\"\n",
    "        # load image and label\n",
    "        img = self.load_image(index)\n",
    "        class_name  = self.paths[index].parent.name # expects path in data_folder/class_name/image.jpg(.png, .jpeg)\n",
    "        class_idx = self.class_to_idx[class_name]\n",
    "        label = class_idx\n",
    "        # load corresponding metadata\n",
    "        metadata_csv = pd.read_csv(self.metadata_file, index_col='img_id') # or other header names\n",
    "        img_id = self.paths[index].name.replace('.jpg', '') # .png, .jpeg\n",
    "        img_metadata = metadata_csv.loc[img_id]\n",
    "        metadata = torch.Tensor(img_metadata.values)\n",
    "        # transform for applying data augmentation with albumentations library\n",
    "        img = np.array(img)\n",
    "        return self.transform(image=img)['image'], metadata, label # return (img, metadata, label): (X, fv, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Build the Multimodal Bayesian Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 300\n",
    "num_classes = 6\n",
    "_, transform_normal = get_transforms(img_size)\n",
    "\n",
    "# 1. DEFINE THE STRUCTURE AND LOAD THE PARAMETERS FOR CONVOLUTIONAL NEURAL NETWORK\n",
    "enb3 = timm.create_model('efficientnet_b3', features_only=False, pretrained=False, num_classes=num_classes)\n",
    "enb3.load_state_dict(torch.load('CNN_params.pt', map_location=torch.device('cpu')))\n",
    "enb3.eval()\n",
    "\n",
    "# 2. DEFINE THE STRUCTURE AND LOAD THE PARAMETERS FOR BAYESIAN NETWORK\n",
    "pyro.clear_param_store()\n",
    "best_params = torch.load('BN_params.pt', map_location=torch.device('cpu'))\n",
    "# first layer\n",
    "### CNN latent variable: use the Softmax-ed output of CNN directly as the parameter of the distribution ###\n",
    "# second layer\n",
    "diagnosis_probs_param = best_params[6]\n",
    "# third layer\n",
    "itch_probs_param = best_params[0]\n",
    "grew_probs_param = best_params[1]\n",
    "hurt_probs_param = best_params[2]\n",
    "changed_probs_param = best_params[3]\n",
    "bleed_probs_param = best_params[4]\n",
    "elevation_probs_param = best_params[5]\n",
    "site_probs_param = best_params[7]\n",
    "diameter_probs_param = best_params[8]\n",
    "age_probs_param = best_params[9]\n",
    "\n",
    "@config_enumerate\n",
    "def model(img_obs, itch_obs, grew_obs, hurt_obs, changed_obs, bleed_obs, elevation_obs, site_obs, diameter_obs, age_obs, diagnosis_obs=None):\n",
    "    # parameters\n",
    "    # first layer \n",
    "    ### CNN latent variable: use the Softmax-ed output of CNN directly as the parameter of the distribution ###\n",
    "    # second layer\n",
    "    diagnosis_probs = pyro.param('diagnosis_probs', diagnosis_probs_param, constraint=constraints.simplex)\n",
    "    # third layer\n",
    "    itch_probs = pyro.param('itch_probs', itch_probs_param, constraint=constraints.simplex)\n",
    "    grew_probs = pyro.param('grew_probs', grew_probs_param, constraint=constraints.simplex)\n",
    "    hurt_probs = pyro.param('hurt_probs', hurt_probs_param, constraint=constraints.simplex)\n",
    "    changed_probs = pyro.param('changed_probs', changed_probs_param, constraint=constraints.simplex)\n",
    "    bleed_probs = pyro.param('bleed_probs', bleed_probs_param, constraint=constraints.simplex)\n",
    "    elevation_probs = pyro.param('elevation_probs', elevation_probs_param, constraint=constraints.simplex)\n",
    "    site_probs = pyro.param('site_probs', site_probs_param, constraint=constraints.simplex)\n",
    "    diameter_probs = pyro.param('diameter_probs', diameter_probs_param, constraint=constraints.simplex)\n",
    "    age_probs = pyro.param('age_probs', age_probs_param, constraint=constraints.simplex)\n",
    "\n",
    "    # distributions\n",
    "    # first layer\n",
    "    CNN = pyro.sample('img_latent_variable', dist.Categorical(probs=(nn.Softmax()(enb3(img_obs)))))\n",
    "    # second layer\n",
    "    diagnosis = pyro.sample('diagnosis', dist.Categorical(probs=diagnosis_probs[(CNN).long()]), obs=diagnosis_obs)\n",
    "    # third layer\n",
    "    itch = pyro.sample('itch', dist.Categorical(probs=itch_probs[(CNN*6+diagnosis).long()]), obs=itch_obs)\n",
    "    grew = pyro.sample('grew', dist.Categorical(probs=grew_probs[(CNN*6+diagnosis).long()]), obs=grew_obs)\n",
    "    hurt = pyro.sample('hurt', dist.Categorical(probs=hurt_probs[(CNN*6+diagnosis).long()]), obs=hurt_obs)\n",
    "    changed = pyro.sample('changed', dist.Categorical(probs=changed_probs[(CNN*6+diagnosis).long()]), obs=changed_obs)\n",
    "    bleed = pyro.sample('bleed', dist.Categorical(probs=bleed_probs[(CNN*6+diagnosis).long()]), obs=bleed_obs)\n",
    "    elevation = pyro.sample('elevation', dist.Categorical(probs=elevation_probs[(CNN*6+diagnosis).long()]), obs=elevation_obs)\n",
    "    site = pyro.sample('site', dist.Categorical(probs=site_probs[(CNN*6+diagnosis).long()]), obs=site_obs)\n",
    "    diameter = pyro.sample('diameter', dist.Categorical(probs=diameter_probs[(CNN*6+diagnosis).long()]), obs=diameter_obs)\n",
    "    age = pyro.sample('age', dist.Categorical(probs=age_probs[(CNN*6+diagnosis).long()]), obs=age_obs)\n",
    "    return diagnosis\n",
    "\n",
    "def guide(img_obs, itch_obs, grew_obs, hurt_obs, changed_obs, bleed_obs, elevation_obs, site_obs, diameter_obs, age_obs, diagnosis_obs=None):\n",
    "    pass\n",
    "\n",
    "# 3. DEFINE THE INFERENCE PROCESS\n",
    "def predict(img_obs, itch_obs=None, grew_obs=None, hurt_obs=None, changed_obs=None, bleed_obs=None, elevation_obs=None, site_obs=None, diameter_obs=None, age_obs=None):\n",
    "    conditional_marginals = TraceEnum_ELBO().compute_marginals(model, guide, img_obs=img_obs, itch_obs=itch_obs, grew_obs=grew_obs, hurt_obs=hurt_obs, changed_obs=changed_obs, bleed_obs=bleed_obs, elevation_obs=elevation_obs, site_obs=site_obs, diameter_obs=diameter_obs, age_obs=age_obs)\n",
    "    diagnosis_prob_0 = conditional_marginals['diagnosis'].log_prob(torch.tensor(0)).exp().reshape(1, 1)\n",
    "    diagnosis_prob_1 = conditional_marginals['diagnosis'].log_prob(torch.tensor(1)).exp().reshape(1, 1)\n",
    "    diagnosis_prob_2 = conditional_marginals['diagnosis'].log_prob(torch.tensor(2)).exp().reshape(1, 1)\n",
    "    diagnosis_prob_3 = conditional_marginals['diagnosis'].log_prob(torch.tensor(3)).exp().reshape(1, 1)\n",
    "    diagnosis_prob_4 = conditional_marginals['diagnosis'].log_prob(torch.tensor(4)).exp().reshape(1, 1)\n",
    "    diagnosis_prob_5 = conditional_marginals['diagnosis'].log_prob(torch.tensor(5)).exp().reshape(1, 1)\n",
    "    diagnosis_probs = torch.cat((diagnosis_prob_0, diagnosis_prob_1, diagnosis_prob_2, diagnosis_prob_3, diagnosis_prob_4, diagnosis_prob_5), dim=0).T\n",
    "    diagnosis_preds = torch.argmax(diagnosis_probs, dim=1)\n",
    "    return diagnosis_preds, diagnosis_probs\n",
    "\n",
    "# 4. EXAMINE THE MODEL ARCHITECTURE\n",
    "img_obs_test = torch.ones(1, 3, img_size, img_size)\n",
    "itch_obs_test = torch.ones(1)\n",
    "grew_obs_test = torch.ones(1)\n",
    "hurt_obs_test = torch.ones(1)\n",
    "changed_obs_test = torch.ones(1)\n",
    "bleed_obs_test = torch.ones(1)\n",
    "elevation_obs_test = torch.ones(1)\n",
    "diagnosis_obs_test = torch.ones(1)\n",
    "site_obs_test = torch.ones(1)\n",
    "diameter_obs_test = torch.ones(1)\n",
    "age_obs_test = torch.ones(1)\n",
    "pyro.render_model(model=model, model_args=(img_obs_test, itch_obs_test, grew_obs_test, hurt_obs_test, changed_obs_test, bleed_obs_test, elevation_obs_test, site_obs_test, diameter_obs_test, age_obs_test, \n",
    "                                           diagnosis_obs_test), render_distributions=True, render_params=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Test Your Own Samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sample_dir = '/img_sample/'\n",
    "metadata_sample_file = '/metadata_sample/metadata_sample.csv'\n",
    "ds_sample = CustomizedImageFolder(img_sample_dir, metadata_sample_file, transform=transform_normal)\n",
    "\n",
    "for i in range(len(ds_sample)):\n",
    "    # get one datapoint\n",
    "    features, embeddings, _ = ds_sample[i]\n",
    "    # assign data for MBN\n",
    "    img_obs = features.reshape(1, 3, img_size, img_size)\n",
    "    itch_obs = embeddings[0]\n",
    "    grew_obs = embeddings[1]\n",
    "    hurt_obs = embeddings[2]\n",
    "    changed_obs = embeddings[3]\n",
    "    bleed_obs = embeddings[4]\n",
    "    elevation_obs = embeddings[5]\n",
    "    site_obs = embeddings[6]\n",
    "    diameter_obs = embeddings[7]\n",
    "    age_obs = embeddings[8]\n",
    "    # calculate the predictions\n",
    "    preds, probs = predict(img_obs, itch_obs, grew_obs, hurt_obs, changed_obs, bleed_obs, elevation_obs, site_obs, diameter_obs, age_obs)\n",
    "    # get top-3 predictions and their probabilities\n",
    "    top_probs_ImageOnly, top_preds_ImageOnly = torch.topk((nn.Softmax()(enb3(img_obs))), 3)\n",
    "    top_probs_ImageMetadata, top_preds_ImageMetadata = torch.topk(probs, 3)\n",
    "    # display the diagnostic results\n",
    "    print('Predicted Diagnosis of \"'+str(os.path.basename(ds_sample.paths[i]))+'\":')\n",
    "    # CNN output\n",
    "    print('\\n<<<<< Image Only >>>>>')\n",
    "    for rank_ImageOnly in range(top_probs_ImageOnly.size(1)):\n",
    "        disease_ImageOnly = {0:'ACK - Actinic Keratosis', 1:'BCC - Basal Cell Carcinoma', 2:'MEL - Malignant Melanoma', \n",
    "                             3:'NEV - Benign Melanocytic Nevus', 4:'SCC - Squamous Cell Carcinoma', 5:'SEK - Seborrheic Keratosis'}.get(top_preds_ImageOnly[0, rank_ImageOnly].item(), 'UNK - Unknown Disease')\n",
    "        probability_ImageOnly = round(100*top_probs_ImageOnly[0, rank_ImageOnly].item(), 1)\n",
    "        print(f'Top {rank_ImageOnly+1}: {disease_ImageOnly} (Probability: {probability_ImageOnly}%, Baseline: {round(100/6, 1)}%)')\n",
    "    # BN output\n",
    "    print('\\n<<<<< Image + Metadata >>>>>')\n",
    "    for rank_ImageMetadata in range(top_probs_ImageMetadata.size(1)):\n",
    "        disease_ImageMetadata = {0:'ACK - Actinic Keratosis', 1:'BCC - Basal Cell Carcinoma', 2:'MEL - Malignant Melanoma', \n",
    "                   3:'NEV - Benign Melanocytic Nevus', 4:'SCC - Squamous Cell Carcinoma', 5:'SEK - Seborrheic Keratosis'}.get(top_preds_ImageMetadata[0, rank_ImageMetadata].item(), 'UNK - Unknown Disease')\n",
    "        probability_ImageMetadata = round(100*top_probs_ImageMetadata[0, rank_ImageMetadata].item(), 1)\n",
    "        print(f'Top {rank_ImageMetadata+1}: {disease_ImageMetadata} (Probability: {probability_ImageMetadata}%, Baseline: {round(100/6, 1)}%)')\n",
    "    # display the thumbnail image\n",
    "    img_thumbnail = Image.open(ds_sample.paths[i])\n",
    "    plt.figure(figsize=(2.5, 2.5))\n",
    "    plt.imshow(img_thumbnail)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d844e3f8642a194b776b23a167f67ed705eb7f693544df137c8957dd067974a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
